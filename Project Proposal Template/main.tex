\documentclass[12pt, a4paper]{report}
\usepackage{graphicx} % For including images
\usepackage{titlesec} % For customizing section titles
\usepackage{tocloft} % For customizing table of contents
\usepackage{acro} % For acronyms
%\usepackage{hyperref} % For clickable links in the document
%% ____Bibliography____%%
\usepackage[numbers,sort&compress]{natbib}
\usepackage{chapterbib}
\usepackage[breaklinks]{hyperref}
%\hypersetup{colorlinks=true,citecolor=blue,linkcolor=blue,urlcolor=blue}
% Page margins
\usepackage[left=1.5in, right=1in, top=1in, bottom=1in]{geometry}

% Remove page number from the first page
\thispagestyle{empty}

% Customize table of contents, list of figures, and list of tables
\renewcommand{\cfttoctitlefont}{\hfill\Large\bfseries}
\renewcommand{\cftaftertoctitle}{\hfill}
\renewcommand{\cftloftitlefont}{\hfill\Large\bfseries}
\renewcommand{\cftafterloftitle}{\hfill}
\renewcommand{\cftlottitlefont}{\hfill\Large\bfseries}
\renewcommand{\cftafterlottitle}{\hfill}

% Define acronyms
\DeclareAcronym{AI}{
  short = AI,
  long  = Artificial Intelligence
}
\DeclareAcronym{ML}{
  short = ML,
  long  = Machine Learning
}
\DeclareAcronym{UML}{
  short = UML,
  long  = Unified Modeling Language
}
\DeclareAcronym{NLP}{
  short = NLP,
  long  = Natural Language Processing
}
\DeclareAcronym{DL}{
  short = DL,
  long  = Deep Learning
}
\begin{document}

\include{cover}

\renewcommand{\thepage}{\roman{page}} % Start page numbering in roman

\chapter*{Abstract}
The growing complexity of modern software systems and the need for effective communication among stakeholders have made Unified Modeling Language (UML) diagrams a vital component of software engineering. However, manually creating UML diagrams from textual requirements is a time-consuming, error-prone process that requires considerable expertise. To address this challenge, this research proposes an AI-driven framework for automatically generating UML class and use case diagrams from natural language software requirements.

The proposed system leverages advanced Natural Language Processing (NLP) and Deep Learning (DL) techniques to interpret unrestricted, ambiguous, and incomplete textual inputs more accurately. By improving grammatical and semantic understanding, the framework aims to produce more reliable and comprehensive UML representations.

The methodology includes both quantitative and qualitative evaluation. Accuracy is measured using standard metrics such as precision, recall, and F1-score, while usability is assessed through feedback from students and industry professionals. A comparative analysis with existing tools demonstrates that the proposed approach offers improved scalability, robustness, and efficiency.

This research contributes to the field of software engineering by reducing manual effort, enhancing design accuracy, and improving collaboration among stakeholders. By automating UML diagram generation, the proposed framework supports more efficient and adaptive software development workflows, benefiting both academic research and industrial practice.
\newpage

% Table of Contents
\tableofcontents
\newpage

% List of Figures
\listoffigures
\newpage

% List of Tables
\listoftables
\newpage

% Acronyms
\addcontentsline{toc}{chapter}{Acronyms} % Add to table of contents
\acuseall % Use all acronyms to ensure they appear in the list
\printacronyms
\newpage

\renewcommand{\thepage}{\arabic{page}} % Start page numbering in arabic 
\setcounter{page}{1} % start page numbering from 1

% Main Content
\chapter{Introduction}
\section{Background}
The rapid growth of technology and the expanding influence of the software and IT industry have significantly transformed how individuals and organizations operate. Software applications now play a central role in driving innovation across domains such as healthcare, education, finance, and entertainment. As software systems become more complex, the demand for efficient, accurate, and collaborative software development processes has increased. Effective communication tools and clear design methodologies are essential to ensure a shared understanding among all stakeholders involved in software projects.

Unified Modeling Language (UML) diagrams are widely used to represent software designs in a standardized and visual manner. They help illustrate system components, interactions, and workflows, making them understandable to both technical and non-technical users. However, creating UML diagrams manually from textual software requirements is a time-consuming and expertise-dependent task. This process often leads to inconsistencies, misinterpretations, and inefficiencies, especially in large-scale projects where speed and accuracy are critical.

Recent advancements in Artificial Intelligence (AI), particularly in Natural Language Processing (NLP) and Deep Learning (DL), provide a promising solution to this problem. NLP enables machines to understand and analyze human language, while DL models can learn complex patterns and generate meaningful outputs. By leveraging these technologies, our project aims to automate the generation of UML diagrams---specifically class diagrams and use case diagrams---from natural language software requirements. This approach seeks to provide a more comprehensive and practical solution for software design automation.

Existing automated systems face several limitations, including the inability to handle incomplete requirement documents, restrictions on sentence structure, and difficulties in understanding grammatical nuances. These issues often result in inaccurate or incomplete UML diagrams. Our proposed system addresses these challenges by supporting unrestricted natural language input, improving grammatical analysis, and handling missing information more effectively.

From a practical and commercial perspective, automating UML diagram generation can significantly reduce development time and cost. It can improve team productivity, enhance collaboration among distributed teams, and ensure consistency in design documentation. By improving efficiency, accuracy, and scalability, our solution can help organizations gain a competitive advantage in today's fast-paced software industry.

This project proposes a robust AI-driven framework that converts textual software requirements into accurate UML diagrams. By bridging the gap between natural language and visual system models, our work contributes to the integration of AI technologies into the software development lifecycle.

\section{Problem Statement}
Despite the significant role that UML diagrams play in software development, existing tools for generating them from natural language requirements have several limitations. Most current solutions focus primarily on class diagrams, while neglecting other important diagram types such as use case diagrams. Furthermore, these tools struggle with incomplete requirement documents, restricted input formats, and grammatical inconsistencies, which often result in errors and inefficiencies. As a result, considerable manual intervention is required, reducing the scalability, accuracy, and practicality of these systems in real-world software development environments.

\section{Aim}

The aim of this project is to develop a comprehensive deep learning--based framework that automatically generates accurate UML class and use case diagrams from natural language software requirements. The framework will address key challenges such as ambiguity, incomplete or unrestricted textual inputs, and grammatical inconsistencies. By improving automation in software design, the project seeks to enhance efficiency, accuracy, and consistency in software development practices.

\section{Objectives}

To achieve the above aim, the following objectives are defined:

\begin{itemize}
    \item \textbf{RO1:} To review and summarize preprocessing techniques and key features used in existing literature for automated UML diagram generation.
    
    \item \textbf{RO2:} To develop methods for handling incomplete, ambiguous, and unrestricted textual inputs, with improved grammatical processing for more precise UML diagrams.
    
    \item \textbf{RO3:} To design and implement a deep learning--based system capable of generating UML class and use case diagrams from natural language software requirements.
    
    \item \textbf{RO4:} To evaluate the adaptability, efficiency, and performance of the proposed system across different domains and types of software requirements.
\end{itemize}

\section{Scope of the Project}

The scope of this project includes:

\begin{itemize}
    \item Automatic generation of UML Class Diagrams and Use Case Diagrams
    \item Processing of unrestricted natural language software requirements
    \item Use of Natural Language Processing (NLP) and Deep Learning techniques
    \item Handling ambiguous, incomplete, and grammatically inconsistent inputs
    \item Evaluation using accuracy metrics such as precision, recall, and F1-score
    \item Basic usability testing with students or software practitioners
\end{itemize}

The project does not cover:

\begin{itemize}
    \item Other UML diagrams such as sequence, activity, or state diagrams
    \item Full industrial-scale deployment
    \item Domain-specific customization for every software field
\end{itemize}

\section{Research Questions}

\begin{itemize}
    \item \textbf{RQ1:} What preprocessing techniques and key features are commonly used in existing literature for automating UML diagram generation?  
    \textit{(Addresses RO1)}
    
    \item \textbf{RQ2:} How can methods be developed to handle incomplete, ambiguous, and unrestricted textual inputs while improving grammatical processing for accurate UML diagram generation?  
    \textit{(Addresses RO2)}
    
    \item \textbf{RQ3:} How can a deep learning--based framework be implemented to generate accurate UML class and use case diagrams from natural language software requirements?  
    \textit{(Addresses RO3)}
    
    \item \textbf{RQ4:} How adaptable and efficient is the proposed framework across different domains and varying software requirements?  
    \textit{(Addresses RO4)}
\end{itemize}


\chapter{Literature Review}
\section{Previous Work}
%Discuss relevant previous work in the field. For instance, \cite{jones2019ml} discusses advancements in \ac{ML}.
The extraction of UML class diagrams from informal software requirements has traditionally been addressed using Natural Language Processing (NLP) techniques combined with heuristic rules or domain ontologies. Over time, researchers have explored more advanced approaches, including machine learning (ML) and deep learning (DL), to improve automation, accuracy, and efficiency. Existing studies mainly fall into three categories: NLP-based, ML-based, and DL-based approaches \cite{ref7}.

\subsubsection{NLP-Based Approaches}

Ibrahim and Ahmad introduced the RACE tool, which uses NLP techniques to analyze software requirements and extract UML class diagrams. The process includes structural analysis, refinement of diagram elements, and validation of UML concepts. However, the generated diagrams often lack complete information \cite{ref8}.

Kumar and Sanyal developed the SUGAR tool using the Rational Unified Process (RUP) methodology. It generates UML class diagrams from natural language requirements by first creating use case diagrams and then linking them to class diagram components. This approach supports object-oriented analysis but still relies heavily on predefined structures \cite{ref9}.

Sharma et al. proposed the Functional Design Creation Tool (FDCT), which preprocesses and analyzes requirements to identify model entities and integrate them into high-level class diagrams \cite{ref10}.

Deeptimahanti and Sanyal introduced UMGAR, a semi-automatic system that uses syntactic rules and analysis trees to extract UML elements. Although it can generate multiple UML diagram types, it requires human intervention to refine relationships and remove irrelevant elements \cite{ref11}.

Similarly, the RAPID tool by More and Phalnikar can generate use case, sequence, and collaboration diagrams using an architecture similar to RACE \cite{ref12}.

Shinde et al. developed a system that applies NLP preprocessing and rule-based extraction to generate UML class and sequence diagrams, and even produce Java source code from the extracted models \cite{ref13}.

The UDRA tool by Amune and Naik combines NLP with domain ontologies to generate various UML diagrams such as class, object, package, and deployment diagrams. It supports relationships like association, generalization, and composition \cite{ref4}.

Other language-specific approaches include the work of Jaiwai and Sammapun, who developed a system for Thai-language requirements, and Utama and Jang, who used SpaCy with linguistic rules to extract UML class diagrams from unrestricted natural language \cite{ref5}.

Abdelnabi et al. proposed an NLP and heuristic-based method for generating class diagrams from informal requirements \cite{ref13}.

Bashir et al. developed the READ tool, which uses the NLTK library and rule-based extraction to automatically identify classes, attributes, and operations. Their results showed improved accuracy compared to earlier tools \cite{ref14, ref15}.

\subsubsection{Machine Learning and Deep Learning Approaches}

Although NLP-based systems improved automation, they still struggle with ambiguity, incompleteness, and uncertainty in natural language requirements \cite{ref16}.

Arachchi proposed a hybrid system that combines NLP, machine learning, and deep learning to generate UML class and use case diagrams. The system uses NLP for text processing, Naive Bayes for classification, and RNNs for identifying actors, classes, and relationships \cite{ref17}.

Saini et al. introduced DoMoBOT, which integrates NLP with ML and DL models to generate domain models as UML class diagrams. The system preprocesses text using SpaCy, extracts domain concepts using NLP rules, refines them using trained ML/DL models, and integrates the results into a final UML model \cite{ref6}.

Rigou and Khriss proposed a deep learning-based framework using Bi-LSTM, BERT, and GPT-2 models to extract UML class diagrams from natural language requirements. Their system identifies entities, removes redundant references, and classifies relationships using neural networks. Results showed that larger training datasets improved diagram accuracy \cite{ref17, ref18}.

\section{Gaps in Literature}
Despite significant progress, several limitations remain in existing UML diagram extraction systems:

\begin{itemize}
    \item \textbf{Limited Diagram Coverage:} Most tools primarily focus on generating UML class diagrams, while other important diagram types such as use case diagrams, sequence diagrams, and activity diagrams receive less attention.
    
    \item \textbf{Dependence on Rule-Based Systems:} Many approaches rely on fixed linguistic rules and heuristics, making them less flexible when dealing with diverse writing styles, complex sentence structures, or informal requirements.
    
    \item \textbf{Handling of Incomplete Requirements:} Existing systems struggle to generate accurate diagrams when requirement documents are missing key information, leading to incomplete or incorrect UML models.
    
    \item \textbf{Grammatical and Semantic Challenges:} Ambiguity, grammatical inconsistencies, and contextual misunderstandings in natural language often cause extraction errors, even in advanced NLP-based tools.
    
    \item \textbf{High Manual Intervention:} Several systems require human input to refine relationships, remove irrelevant elements, or correct extracted models, reducing scalability and automation.
    
    \item \textbf{Limited Real-World Scalability:} Many tools are tested only on small datasets or controlled inputs, making their performance in large-scale, real-world projects uncertain.
    
    \item \textbf{Restricted Input Formats:} Some systems require standardized or structured requirements, limiting their usability with freely written natural language documents.
\end{itemize}

\chapter{Methodology}
\section{Research Design}
In addition to the initial literature review and problem analysis, this research adopts a \textbf{constructive research methodology} to design, develop, and evaluate an AI-driven framework for automating UML diagram generation from natural language software requirements. The methodology is structured into several sequential stages, as illustrated in Figure~1 and Figure~2.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.95\textwidth]{Proposed Methodology.png} % Replace with your image file
    \caption{proposed Methodology}
    
\end{figure}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.95\textwidth]{Proposed Model.png} % Replace with your image file
    \caption{proposed Model}
    
\end{figure}
\subsection{Requirement Analysis}
The process begins with the collection and analysis of natural language software requirements from academic datasets, industry documentation, and open-source repositories. This stage focuses on identifying ambiguities, inconsistencies, and missing information within the textual requirements to understand real-world challenges in requirement interpretation.

\subsection{Preprocessing using NLP}
The collected text is preprocessed using Natural Language Processing (NLP) techniques such as tokenization, part-of-speech (POS) tagging, dependency parsing, and coreference resolution. These steps help normalize the input text, resolve pronoun references, and improve grammatical clarity for accurate information extraction.

\subsection{Sentence Classification}
Each sentence is classified into UML-related categories such as \textit{class definitions, relationships, use cases, and actors}. Transformer-based deep learning models, including BERT and GPT, are used to capture semantic meaning and contextual dependencies in the text.

\subsection{UML Element Extraction}
Relevant UML components such as classes, attributes, associations, and use cases are extracted from the classified sentences. Linguistic features and semantic patterns are analyzed to ensure accurate identification of structural and behavioral elements.

\subsection{UML Diagram Generation}
The extracted elements are converted into UML diagrams using tools such as \textbf{PlantUML} and \textbf{Graphviz}. The framework supports the generation of both \textit{class diagrams} and \textit{use case diagrams}, ensuring coverage of system structure and functionality.

\subsection{Evaluation and Validation}
The generated UML diagrams are evaluated using standard metrics such as \textbf{precision, recall, and F1-score} to measure accuracy. Usability testing is conducted with software engineering students and professionals to assess clarity, usefulness, and practical applicability. Comparative analysis with existing tools highlights improvements in efficiency, scalability, and automation.

\section{Application of the Proposed Model}

The proposed framework has wide applicability across multiple domains in software engineering and education.

\subsection{Software Development Projects}
The system enables automatic generation of UML diagrams from textual requirements, reducing manual effort and improving consistency. This is especially useful in \textit{Agile environments}, where rapid documentation is essential.

\subsection{Education and Training}
Students can focus on understanding system design rather than manual diagram creation. Educators can use the tool to assess projects efficiently.

\subsection{Requirements Engineering}
Analysts can visualize stakeholder requirements early in the development lifecycle, reducing ambiguities and improving client validation.

\subsection{Industry Domains}
The framework is suitable for domains such as \textit{healthcare, finance, and education}, where complex workflows and regulatory compliance require precise system modeling.

\section{Evaluation Plan}

The evaluation strategy ensures the reliability, scalability, and effectiveness of the proposed framework.

\subsection{Dataset Selection}
Datasets include academic sources, industry case studies, and open-source documentation to ensure diversity and linguistic complexity.

\subsection{Evaluation Metrics}
\begin{itemize}
    \item \textbf{Accuracy:} Precision, Recall, F1-score
    \item \textbf{Completeness:} Comparison with ground-truth UML diagrams
    \item \textbf{Scalability:} Runtime and resource usage
\end{itemize}

\subsection{Experimental Validation}
The system is compared with existing UML automation tools using benchmark datasets and real-world case studies.

\subsection{Usability Testing}
Surveys and interviews gather feedback on diagram clarity, usability, and practical value.

\subsection{Error Analysis}
Misclassifications are analyzed to improve handling of ambiguous and incomplete inputs.

\subsection{Discussion}

The proposed framework introduces a robust AI-based solution for automating UML diagram generation using advanced NLP and deep learning techniques. By supporting both \textit{class} and \textit{use case diagrams}, the model addresses structural and behavioral system representations. Its ability to process \textit{unrestricted and ambiguous text} makes it suitable for real-world requirements.

The use of transformer models such as BERT and GPT enables deep semantic understanding, while integration with PlantUML ensures industry-standard outputs. Although challenges such as computational cost and domain adaptability remain, the framework significantly improves efficiency, reduces manual effort, and enhances collaboration among stakeholders.


\section{Data Collection}
To train and evaluate the proposed AI-driven UML generation framework, a diverse and high-quality dataset of natural language software requirements will be collected from multiple reliable sources. The data collection process will focus on ensuring linguistic diversity, domain variety, and real-world relevance.

\subsection{Data Sources}
The dataset will be compiled from the following sources:

\begin{itemize}
    \item \textbf{Open-source Software Repositories:} Requirement documents, user stories, and project descriptions will be extracted from platforms such as GitHub, SourceForge, and GitLab.
    \item \textbf{Academic Datasets:} Publicly available datasets used in software engineering and NLP research will be utilized to ensure benchmark comparability.
    \item \textbf{Industry Case Studies:} Sample requirement documents from industry projects (where permitted) will be included to reflect real-world complexity.
    \item \textbf{Synthetic Data Generation:} Artificial requirement texts will be generated to simulate incomplete, ambiguous, and unstructured requirements.
\end{itemize}

\subsection{Data Types}
The collected data will include:

\begin{itemize}
    \item Functional and non-functional requirements
    \item User stories
    \item Use case descriptions
    \item Software specification documents
\end{itemize}

\subsection{Data Annotation}
The dataset will be manually and semi-automatically annotated with:

\begin{itemize}
    \item UML classes
    \item Attributes
    \item Relationships
    \item Use cases
    \item Actors
\end{itemize}

These annotations will serve as ground truth for training and evaluating the deep learning model.

\subsection{Data Preprocessing}
Before model training, the collected data will be cleaned and standardized by:

\begin{itemize}
    \item Removing noise and irrelevant text
    \item Resolving pronouns using coreference tools
    \item Correcting grammatical inconsistencies
    \item Normalizing sentence structures
\end{itemize}

\subsection{Ethical Considerations}
All data will be collected from publicly available or authorized sources. Any sensitive or proprietary information will be anonymized to ensure privacy and compliance with ethical research standards.


\chapter{Timeline and Resource Required}

\section{Timeline}
\begin{table}[h]
\centering
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{|c|p{7cm}|p{5cm}|}
\hline
\textbf{Time Period} & \textbf{Activities} & \textbf{Deliverables} \\
\hline
Month 1--2 &
\begin{itemize}
    \item Conduct literature review on UML automation
    \item Study existing NLP and AI-based tools
    \item Identify challenges and refine problem statement
\end{itemize}
&
\begin{itemize}
    \item Literature Review Report
    \item Refined Problem Statement
\end{itemize}
\\
\hline

Month 3--4 &
\begin{itemize}
    \item Prepare training and testing dataset
    \item Design preprocessing pipeline (tokenization, POS tagging, parsing)
    \item Explore NLP and DL models (BERT, GPT)
\end{itemize}
&
\begin{itemize}
    \item Prepared Dataset
    \item Preprocessing Pipeline Design
\end{itemize}
\\
\hline

Month 5--6 &
\begin{itemize}
    \item Implement AI-based UML extraction model
    \item Train and fine-tune the model
    \item Generate UML class and use case diagrams
    \item Integrate PlantUML / Graphviz
\end{itemize}
&
\begin{itemize}
    \item Working UML Generation System
    \item Generated UML Diagrams
\end{itemize}
\\
\hline

Month 7 &
\begin{itemize}
    \item Evaluate using precision, recall, F1-score
    \item Compare with existing tools
    \item Conduct usability testing
\end{itemize}
&
\begin{itemize}
    \item Evaluation Report
    \item Performance Comparison Results
\end{itemize}
\\
\hline

Month 8 &
\begin{itemize}
    \item Finalize system
    \item Write final report
    \item Prepare presentation and documentation
\end{itemize}
&
\begin{itemize}
    \item Final Project Report
    \item Presentation Slides
    \item System Documentation
\end{itemize}
\\
\hline
\end{tabular}
\caption{8-Month Project Work Plan}
\end{table}

\section{Resource Required}
\begin{table}[h]
\centering
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{|p{4cm}|p{8cm}|}
\hline
\textbf{Resource Category} & \textbf{Description} \\
\hline

NLP Tools &
SpaCy, NLTK, and Coreferee will be used for text preprocessing tasks such as tokenization, part-of-speech tagging, dependency parsing, and coreference resolution. These tools help extract linguistic features required for UML diagram generation. \\
\hline

Deep Learning Frameworks &
TensorFlow and PyTorch will be used to develop and train deep learning models. Pretrained transformer models such as BERT, GPT, or RoBERTa will be used for feature extraction and classification. \\
\hline

Diagram Generation Tools &
PlantUML and Graphviz will be used to automatically generate UML class and use case diagrams. These tools support multiple UML diagram types and allow customization according to UML standards. \\
\hline

Data Storage and Management &
PostgreSQL or MongoDB will be used to store datasets, training results, and generated UML models in an organized manner. \\
\hline

Hardware Resources &
A computer with sufficient processing power (GPU support preferred), at least 8GB RAM, and stable internet access for model training and testing. \\
\hline

Software Tools &
Python, VS Code, GitHub for version control, and LaTeX for documentation and report writing. \\
\hline

\end{tabular}
\caption{Resource Requirements for the Project}
\end{table}
\chapter{Conclusion}
This research proposes a robust AI-driven framework for automating the generation of UML diagrams from natural language software requirements. By addressing key challenges such as ambiguity, incomplete inputs, and grammatical inconsistencies, the proposed system enhances the accuracy and efficiency of software design processes. The integration of advanced Natural Language Processing (NLP) and Deep Learning (DL) techniques enables scalable automation and supports multiple UML diagram types, thereby improving collaboration among stakeholders.

The proposed methodology, supported by rigorous evaluation and validation, ensures that the framework is practical and suitable for real-world software engineering applications. Although certain limitations, including scalability and domain-specific adaptability, require further investigation, this research establishes a strong foundation for incorporating AI-based solutions into the software development lifecycle.

The outcomes of this study have the potential to transform how software designs are documented and communicated, offering significant benefits to both academia and industry. Future work will focus on extending support for additional UML diagram types, enhancing domain adaptability, and refining evaluation methods to further improve the effectiveness of AI-driven software design automation.

% References
\renewcommand{\bibname}{References}
\bibliographystyle{ieeetr}
\addcontentsline{toc}{chapter}{References} % Add to table of contents
\bibliography{bibliography} 
%\printbibliography

\end{document}